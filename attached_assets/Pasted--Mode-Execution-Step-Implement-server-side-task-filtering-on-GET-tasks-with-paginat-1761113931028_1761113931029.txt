[Mode: Execution]

**Step:** Implement **server-side task filtering** on `GET /tasks` with pagination + sorting (backbone for shared views and bulk actions).

**Why it matters:** This locks your API contract now so UI tabs, reports, and automations reuse the same query shapes—no rewires later.

**Inputs needed:** Existing `server/index.js` (Express) and Postgres access via `../lib/db`. Task columns used: `status, assignee_id, project_id, due_date, title, description, updated_at, created_at`.

**Command (paste at repo root):**

````bash
# 1) Service: composable filters with validation + safe sorting/pagination
mkdir -p server/services
cat > server/services/taskQuery.js <<'JS'
const { pool } = require('../lib/db');

const ALLOWED_STATUS = ['Backlog','In Progress','Blocked','Review','Done','Cancelled'];
const ALLOWED_SORT = new Set(['created_at','updated_at','due_date','title','status']);
const DEFAULT_LIMIT = 20;
const MAX_LIMIT = 100;

function parseList(val) {
  return String(val || '')
    .split(',')
    .map(s => s.trim())
    .filter(Boolean);
}

function parseQuery(qs = {}) {
  const allowed = new Set([
    'status','assignee','project','due_from','due_to','q','page','limit','sort'
  ]);

  // Guard unknown params (helps prevent accidental cache-busters)
  for (const k of Object.keys(qs)) {
    if (!allowed.has(k)) {
      const err = new Error(`Unknown query param: ${k}`);
      err.status = 400;
      throw err;
    }
  }

  const page = Math.max(1, parseInt(qs.page || '1', 10) || 1);
  const limit = Math.min(
    MAX_LIMIT,
    Math.max(1, parseInt(qs.limit || String(DEFAULT_LIMIT), 10) || DEFAULT_LIMIT)
  );

  let sortCol = 'updated_at';
  let sortDir = 'desc';
  if (qs.sort) {
    const [col, dir] = String(qs.sort).split(':');
    if (!ALLOWED_SORT.has(col)) {
      const err = new Error(`Invalid sort column: ${col}`);
      err.status = 400; throw err;
    }
    sortCol = col;
    sortDir = (dir || 'desc').toLowerCase() === 'asc' ? 'asc' : 'desc';
  }

  let status = [];
  if (qs.status) {
    const raw = parseList(qs.status);
    // allow synonyms
    status = raw.map(s => {
      if (s.toLowerCase() === 'overdue') return 'OVERDUE_SENTINEL';
      const found = ALLOWED_STATUS.find(x => x.toLowerCase() === s.toLowerCase());
      return found || s;
    });
  }

  const filters = {
    status,
    assignee: qs.assignee || null,
    project: qs.project || null,
    due_from: qs.due_from || null,
    due_to: qs.due_to || null,
    q: qs.q || null,
    page,
    limit,
    sortCol,
    sortDir
  };
  return filters;
}

/**
 * Fetch filtered tasks with total count.
 * Special case: if status includes OVERDUE_SENTINEL, we add (is_overdue = true) OR (due_date < today and not Done/Cancelled)
 */
async function fetchTasks(filters) {
  const {
    status, assignee, project, due_from, due_to, q,
    page, limit, sortCol, sortDir
  } = filters;

  const where = [];
  const vals = [];
  let i = 1;

  // Core visibility rule (extend with RBAC if needed)
  // Example: none added here; rely on requireAuth upstream.

  // Status filter (excluding special overdue sentinel)
  const cleanStatus = (status || []).filter(s => s !== 'OVERDUE_SENTINEL');
  if (cleanStatus.length > 0) {
    where.push(`t.status = ANY($${i++})`);
    vals.push(cleanStatus);
  }

  // Overdue sentinel
  const wantsOverdue = (status || []).includes('OVERDUE_SENTINEL');
  if (wantsOverdue) {
    where.push(`(
      t.is_overdue = true
      OR (
        t.due_date IS NOT NULL
        AND t.due_date < (DATE_TRUNC('day', (now() AT TIME ZONE 'America/Toronto'))) AT TIME ZONE 'America/Toronto'
        AND t.status NOT IN ('Done','Cancelled')
      )
    )`);
  }

  if (assignee) {
    where.push(`t.assignee_id = $${i++}`);
    vals.push(assignee);
  }
  if (project) {
    where.push(`t.project_id = $${i++}`);
    vals.push(project);
  }
  if (due_from) {
    where.push(`t.due_date >= $${i++}::timestamptz`);
    vals.push(due_from);
  }
  if (due_to) {
    where.push(`t.due_date <= $${i++}::timestamptz`);
    vals.push(due_to);
  }
  if (q) {
    // simple ILIKE search on title/description
    where.push(`(t.title ILIKE $${i} OR t.description ILIKE $${i})`);
    vals.push(`%${q}%`); i++;
  }

  const offset = (page - 1) * limit;
  const whereSql = where.length ? `WHERE ${where.join(' AND ')}` : '';

  const orderSql = `ORDER BY t.${sortCol} ${sortDir}, t.id ASC`;

  const sql = `
    SELECT t.id, t.title, t.status, t.assignee_id, t.project_id,
           t.due_date, t.updated_at, t.created_at, t.is_overdue
    FROM tasks t
    ${whereSql}
    ${orderSql}
    LIMIT $${i++} OFFSET $${i++}
  `;
  vals.push(limit, offset);

  const countSql = `
    SELECT COUNT(*)::int AS total
    FROM tasks t
    ${whereSql}
  `;

  const client = await pool.connect();
  try {
    const [rowsRes, countRes] = await Promise.all([
      client.query(sql, vals),
      client.query(countSql, vals.slice(0, vals.length - 2)) // count doesn't use limit/offset
    ]);
    return {
      items: rowsRes.rows,
      total: countRes.rows[0].total,
      page,
      limit
    };
  } finally {
    client.release();
  }
}

module.exports = { parseQuery, fetchTasks };
JS

# 2) Route: extend GET /tasks to use filters safely
applypatch <<'PATCH'
*** Begin Patch
*** Update File: server/index.js
@@
 const express = require('express');
 const app = express();
@@
 const { fetchStuck, fetchUpcoming } = require('./services/reportingWindows');
+const { parseQuery, fetchTasks } = require('./services/taskQuery');
 
 // ...existing routes
 
+// Filtered tasks listing with pagination/sorting
+app.get('/tasks', requireAuth(), async (req, res, next) => {
+  try {
+    const filters = parseQuery(req.query);
+    const result = await fetchTasks(filters);
+    res.json({ ok: true, ...result });
+  } catch (e) {
+    if (e.status) return res.status(e.status).json({ ok: false, error: e.message });
+    next(e);
+  }
+});
*** End Patch
PATCH

# 3) Docs: add query contract with cURL
applypatch <<'PATCH'
*** Begin Patch
*** Update File: docs/api-contract.md
@@
+## Tasks — Filtered Listing
+`GET /tasks`
+
+**Query params**
+- `status`: comma-separated (e.g., `Backlog,In Progress,overdue`)
+- `assignee`: UUID
+- `project`: UUID
+- `due_from`: ISO timestamp
+- `due_to`: ISO timestamp
+- `q`: text search in title/description
+- `page`: 1-based, default 1
+- `limit`: default 20, max 100
+- `sort`: `updated_at|created_at|due_date|title|status` with `:asc|desc` (default `updated_at:desc`)
+
+**Example**
+```bash
+curl "$BASE_URL/tasks?status=overdue,In%20Progress&assignee=<UUID>&due_to=2025-11-01&q=pump&limit=20&page=1&sort=due_date:asc" \
+  -H "Authorization: Bearer $TOKEN"
+```
+
+**200**
+```json
+{ "ok": true, "items": [ { "id":"...", "title":"...", "status":"In Progress", "is_overdue": false, "due_date":"...", "updated_at":"..." } ], "total": 42, "page": 1, "limit": 20 }
+```
*** End Patch
PATCH

# 4) Tests: filter math + pagination + guard unknown param
mkdir -p server/__tests__
cat > server/__tests__/taskQuery.test.js <<'JS'
const { pool } = require('../lib/db');
const { parseQuery, fetchTasks } = require('../services/taskQuery');

describe('task filtering', () => {
  beforeAll(async () => { await pool.query('BEGIN'); });
  afterAll(async () => { await pool.query('ROLLBACK'); await pool.end(); });

  test('parseQuery guards unknown params', () => {
    expect(() => parseQuery({ foo: 'bar' })).toThrow(/Unknown query param/);
  });

  test('fetchTasks filters by status and q', async () => {
    await pool.query(`
      INSERT INTO tasks (title, description, status, updated_at)
      VALUES
      ('Pump install', 'basement scope', 'In Progress', NOW()),
      ('Valve spec', 'includes pump notes', 'Backlog', NOW()),
      ('Archive', 'not visible', 'Done', NOW())
    `);
    const qp = parseQuery({ status:'In Progress,Backlog', q:'pump', limit:'50', page:'1' });
    const res = await fetchTasks(qp);
    const titles = res.items.map(r => r.title);
    expect(titles).toContain('Pump install');
    expect(titles).toContain('Valve spec');
    expect(titles).not.toContain('Archive'); // filtered by status list
    expect(res.total).toBeGreaterThanOrEqual(2);
  });

  test('pagination is stable', async () => {
    const qp = parseQuery({ limit:'1', page:'1', sort:'updated_at:desc' });
    const a = await fetchTasks(qp);
    const qp2 = parseQuery({ limit:'1', page:'2', sort:'updated_at:desc' });
    const b = await fetchTasks(qp2);
    expect(a.items[0]?.id).not.toBe(b.items[0]?.id);
    expect(typeof a.total).toBe('number');
  });
});
JS

# 5) Smoke: add a quick filtered call (non-failing if empty)
applypatch <<'PATCH'
*** Begin Patch
*** Update File: scripts/smoke-api.js
@@
     // 3) tasks (read)
-    const tasks = await jget('/tasks?limit=50');
+    const tasks = await jget('/tasks?limit=50');
     if (!Array.isArray(tasks)) throw new Error('tasks not array');
@@
+    // 3b) filtered query (should not error)
+    await jget('/tasks?status=In%20Progress,Backlog&limit=5&page=1&sort=updated_at:desc');
*** End Patch
PATCH

echo "✅ Filtered tasks API added (service + route + docs + tests + smoke hook)"
````

**Success check:**

* Tests pass:
  `npm test -- server/__tests__/taskQuery.test.js`
* Smoke still green:
  `npm run smoke:api`
* Example request returns deterministic, paginated results:
  `/tasks?status=overdue,In%20Progress&assignee=<UUID>&due_to=2025-11-01&q=pump&limit=20&page=1&sort=due_date:asc`

**Next:** wait for user

Mini-lesson: filter-first design hardens your **data contract**. Once your URLs encode intent (filters, sort, paging), everything else—bulk actions, saved views, CSV/excel exports, and even email digests—can reuse the same endpoints without special-case logic.
