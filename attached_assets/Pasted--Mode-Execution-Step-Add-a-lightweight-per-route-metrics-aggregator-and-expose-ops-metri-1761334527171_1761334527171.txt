[Mode: Execution]

Step: Add a lightweight **per-route metrics aggregator** and expose `/ops/metrics` (JSON) with p50/p95 latency, RPS, and error rate over rolling windows. (Layer: **Velocity → Metrics Core**)

Why it matters: This is Phase 11’s spine. One tiny in-memory module gives you instant KPIs for the Velocity Dashboard without new infra.

Inputs needed:

* Your Express entry (`server.js`)
* Existing request timing hook (we’ll replace/upgrade it)

Command:

1. Create `lib/metrics.js`:

```js
// lib/metrics.js — Velocity/Metrics Core (in-memory)
const now = () => Date.now();

function makeWindow(ms) {
  return { ms, points: [] }; // points: {t, dur_ms, ok}
}

function record(win, dur_ms, ok) {
  const t = now();
  win.points.push({ t, dur_ms, ok });
  // drop old
  const cutoff = t - win.ms;
  while (win.points.length && win.points[0].t < cutoff) win.points.shift();
}

function percentile(arr, p) {
  if (!arr.length) return null;
  const sorted = arr.slice().sort((a,b)=>a-b);
  const idx = Math.min(sorted.length - 1, Math.floor(p * (sorted.length - 1)));
  return sorted[idx];
}

function summarize(win) {
  const pts = win.points;
  const n = pts.length;
  if (!n) return { count: 0, rps: 0, p50_ms: null, p95_ms: null, err_rate: 0 };
  const dur = pts.map(p=>p.dur_ms);
  const okCount = pts.filter(p=>p.ok).length;
  const span_s = win.ms / 1000;
  return {
    count: n,
    rps: +(n / span_s).toFixed(3),
    p50_ms: Math.round(percentile(dur, 0.50)),
    p95_ms: Math.round(percentile(dur, 0.95)),
    err_rate: +(((n - okCount) / n) * 100).toFixed(2), // %
  };
}

function makeMetrics() {
  // windows: 1m, 5m, 15m
  const windows = [60_000, 300_000, 900_000].map(makeWindow);
  const perRoute = new Map(); // key: METHOD path

  function key(req) {
    // collapse query strings; keep path and method
    return `${req.method} ${req.route?.path || req.path}`;
  }

  function tap(req, res, dur_ms, ok) {
    const k = key(req);
    if (!perRoute.has(k)) perRoute.set(k, windows.map(() => makeWindow(60_000))); // clone-like
    // ensure unique window objects per route
    let arr = perRoute.get(k);
    if (arr.length !== windows.length) arr = windows.map(makeWindow), perRoute.set(k, arr);
    arr.forEach(w => record(w, dur_ms, ok));
  }

  function snapshot() {
    const out = {};
    for (const [k, wins] of perRoute.entries()) {
      out[k] = {
        "1m": summarize(wins[0]),
        "5m": summarize(wins[1]),
        "15m": summarize(wins[2]),
      };
    }
    return {
      service: "eden-erp-backend",
      env: process.env.SENTRY_ENV || process.env.NODE_ENV || "dev",
      generated_at: new Date().toISOString(),
      routes: out,
    };
  }

  return { tap, snapshot };
}

module.exports = { makeMetrics };
```

2. Wire middleware in `server.js` (replace the old timing hook):

```js
// Velocity Layer wiring
const { makeMetrics } = require("./lib/metrics");
const metrics = makeMetrics();

app.use((req, res, next) => {
  const start = process.hrtime.bigint();
  res.on("finish", () => {
    const end = process.hrtime.bigint();
    const ms = Number(end - start) / 1e6;
    const ok = res.statusCode < 400;
    metrics.tap(req, res, ms, ok);
    // keep your pino log if present
    if (req.log) req.log.info({ req_id: req.id, duration_ms: ms }, "req_complete");
  });
  next();
});

// Read-only metrics endpoint (no auth; lock down later if needed)
app.get("/ops/metrics", (_req, res) => {
  res.setHeader("Cache-Control", "no-store");
  res.json(metrics.snapshot());
});
```

Success check:

* Hit a few routes, then run:

  ```bash
  curl -s http://localhost:3000/ops/metrics | python3 -m json.tool | head -80
  ```
* You should see per-route entries with `"1m"`, `"5m"`, `"15m"` blocks showing `rps`, `p50_ms`, `p95_ms`, and `err_rate`.

Next: wait for user.
